# MyGPT
Repo for testing a bunch of tricks on GPT models and maybe more

The base model I'll be building on is llama from [my port](https://github.com/Ryu1845/llama-keras-core/) of [minimal-llama](https://github.com/zphang/minimal-llama/blob/e1d44d1712369db3a68a580648b8dc64b7a779ac/minimal_llama/model.py).

This repo is built using [Keras Core](https://github.com/keras-team/keras-core) which is still in experimental phase. Refer to its documentation for specific details

The code is licensed under AGPLv3 if you want another license you can email me.
